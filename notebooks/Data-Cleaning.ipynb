{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81690339-cb99-4a02-93a7-04b329819574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Environment Setup:\n",
      "   Device: cpu\n",
      "   PyTorch Version: 2.8.0+cpu\n",
      "   Pandas Version: 2.3.3\n",
      "   NumPy Version: 2.3.3\n",
      "\n",
      "‚úÖ All libraries imported successfully!\n",
      "üìä Ready to begin customer churn analysis...\n"
     ]
    }
   ],
   "source": [
    "# Essential imports for data science and machine learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                           roc_auc_score, roc_curve, precision_recall_curve,\n",
    "                           f1_score, precision_score, recall_score)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Configure visualization\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Check device availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Environment Setup:\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   PyTorch Version: {torch.__version__}\")\n",
    "print(f\"   Pandas Version: {pd.__version__}\")\n",
    "print(f\"   NumPy Version: {np.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")\n",
    "print(\"üìä Ready to begin customer churn analysis...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf4e928-f346-43c7-9d5e-e53cef444c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading Telco Customer Churn dataset...\n",
      "‚úÖ Data loaded successfully from: ../data/Telco-Customer-Churn.csv\n",
      "\n",
      "üìä Dataset Overview:\n",
      "   Shape: 7,043 rows √ó 21 columns\n",
      "   Memory usage: 6.8 MB\n",
      "\n",
      "üëÄ First 5 rows:\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the customer churn dataset\n",
    "print(\"üì• Loading Telco Customer Churn dataset...\")\n",
    "\n",
    "data_paths = [\n",
    "    '../data/Telco-Customer-Churn.csv'\n",
    "]\n",
    "\n",
    "df = None\n",
    "for path in data_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"‚úÖ Data loaded successfully from: {path}\")\n",
    "        break\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"\\nüìä Dataset Overview:\")\n",
    "print(f\"   Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nüëÄ First 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36243d6f-5750-41f7-9b33-26adf550f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Data Cleaning and Quality Assessment\n",
      "==================================================\n",
      "üìä Starting with 7,043 rows and 21 columns\n"
     ]
    }
   ],
   "source": [
    "# Deep dive into data quality issues\n",
    "print(\"üßπ Data Cleaning and Quality Assessment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_cleaned = df.copy()\n",
    "original_shape = df_cleaned.shape\n",
    "\n",
    "print(f\"üìä Starting with {original_shape[0]:,} rows and {original_shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05106687-f5dd-43de-a768-abfe86021af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1Ô∏è‚É£ Checking for duplicate customers...\n",
      "   Duplicate customerIDs: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Check for duplicate customer IDs\n",
    "print(f\"\\n1Ô∏è‚É£ Checking for duplicate customers...\")\n",
    "duplicate_customers = df_cleaned['customerID'].duplicated().sum()\n",
    "print(f\"   Duplicate customerIDs: {duplicate_customers}\")\n",
    "\n",
    "if duplicate_customers > 0:\n",
    "    print(\"   üîß Removing duplicate customer records...\")\n",
    "    df_cleaned = df_cleaned.drop_duplicates(subset=['customerID'])\n",
    "    print(f\"   ‚úÖ Removed {duplicate_customers} duplicate records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d1adae-48a3-417e-8d53-b5aef122f7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2Ô∏è‚É£ Fixing TotalCharges data type...\n",
      "   Current TotalCharges type: object\n",
      "   Non-numeric TotalCharges values: 11\n",
      "   üîß Converting TotalCharges to numeric...\n",
      "   ‚úÖ TotalCharges converted to numeric type\n"
     ]
    }
   ],
   "source": [
    "# 2. Handle TotalCharges data type issue (common in this dataset)\n",
    "print(f\"\\n2Ô∏è‚É£ Fixing TotalCharges data type...\")\n",
    "print(f\"   Current TotalCharges type: {df_cleaned['TotalCharges'].dtype}\")\n",
    "\n",
    "# Check for non-numeric values in TotalCharges\n",
    "if df_cleaned['TotalCharges'].dtype == 'object':\n",
    "    non_numeric_total = df_cleaned['TotalCharges'].apply(lambda x: not str(x).replace('.', '').replace(' ', '').isdigit())\n",
    "    non_numeric_count = non_numeric_total.sum()\n",
    "    print(f\"   Non-numeric TotalCharges values: {non_numeric_count}\")\n",
    "\n",
    "    if non_numeric_count > 0:\n",
    "        print(\"   üîß Converting TotalCharges to numeric...\")\n",
    "        # Convert to numeric, invalid values become NaN\n",
    "        df_cleaned['TotalCharges'] = pd.to_numeric(df_cleaned['TotalCharges'], errors='coerce')\n",
    "        print(f\"   ‚úÖ TotalCharges converted to numeric type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5f8e3c-4978-43ea-b906-68e85e0f39a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è‚É£ Handling missing values...\n",
      "   Missing values found:\n",
      "      Column  Missing Count  Missing %\n",
      "TotalCharges             11       0.16\n",
      "\n",
      "   üîß Handling 11 missing TotalCharges values...\n",
      "   Tenure stats for missing TotalCharges customers:\n",
      "   Mean tenure: 0.0 months\n",
      "   üí° Missing TotalCharges likely represent new customers\n",
      "   üîß Filling missing TotalCharges with MonthlyCharges (first month)\n",
      "   ‚úÖ TotalCharges missing values handled\n"
     ]
    }
   ],
   "source": [
    "# 3. Handle missing values\n",
    "print(f\"\\n3Ô∏è‚É£ Handling missing values...\")\n",
    "missing_values = df_cleaned.isnull().sum()\n",
    "missing_percent = (missing_values / len(df_cleaned) * 100).round(2)\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Missing %': missing_percent.values\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary['Missing Count'] > 0]\n",
    "\n",
    "if len(missing_summary) > 0:\n",
    "    print(\"   Missing values found:\")\n",
    "    print(missing_summary.to_string(index=False))\n",
    "\n",
    "    # Handle TotalCharges missing values (likely new customers with 0 tenure)\n",
    "    if 'TotalCharges' in missing_summary['Column'].values:\n",
    "        total_charges_missing = df_cleaned['TotalCharges'].isnull().sum()\n",
    "        print(f\"\\n   üîß Handling {total_charges_missing} missing TotalCharges values...\")\n",
    "\n",
    "        # Check if missing TotalCharges correspond to low tenure customers\n",
    "        missing_tenure = df_cleaned[df_cleaned['TotalCharges'].isnull()]['tenure'].describe()\n",
    "        print(f\"   Tenure stats for missing TotalCharges customers:\")\n",
    "        print(f\"   Mean tenure: {missing_tenure['mean']:.1f} months\")\n",
    "\n",
    "        if missing_tenure['mean'] < 3:  # Very new customers\n",
    "            print(\"   üí° Missing TotalCharges likely represent new customers\")\n",
    "            print(\"   üîß Filling missing TotalCharges with MonthlyCharges (first month)\")\n",
    "            df_cleaned['TotalCharges'] = df_cleaned['TotalCharges'].fillna(df_cleaned['MonthlyCharges'])\n",
    "        else:\n",
    "            print(\"   üîß Filling missing TotalCharges with median value\")\n",
    "            df_cleaned['TotalCharges'] = df_cleaned['TotalCharges'].fillna(df_cleaned['TotalCharges'].median())\n",
    "\n",
    "        print(\"   ‚úÖ TotalCharges missing values handled\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No missing values found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a457ad-77d3-4ebe-9088-4a7e448f8081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4Ô∏è‚É£ Checking for outliers...\n",
      "        Column  Outlier Count Outlier % Lower Bound Upper Bound\n",
      "        tenure              0      0.0%      -60.00      124.00\n",
      "MonthlyCharges              0      0.0%      -46.02      171.38\n",
      "  TotalCharges              0      0.0%    -4683.52     8868.67\n"
     ]
    }
   ],
   "source": [
    "# 4. Check for outliers in numerical columns\n",
    "print(f\"\\n4Ô∏è‚É£ Checking for outliers...\")\n",
    "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "outlier_summary = []\n",
    "for col in numerical_cols:\n",
    "    Q1 = df_cleaned[col].quantile(0.25)\n",
    "    Q3 = df_cleaned[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df_cleaned[(df_cleaned[col] < lower_bound) | (df_cleaned[col] > upper_bound)]\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_percent = (outlier_count / len(df_cleaned)) * 100\n",
    "\n",
    "    outlier_summary.append({\n",
    "        'Column': col,\n",
    "        'Outlier Count': outlier_count,\n",
    "        'Outlier %': f\"{outlier_percent:.1f}%\",\n",
    "        'Lower Bound': f\"{lower_bound:.2f}\",\n",
    "        'Upper Bound': f\"{upper_bound:.2f}\"\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(outlier_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28506cc-f574-44ac-a3e8-e05b5d2aee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5Ô∏è‚É£ Validating business logic...\n",
      "   Customers with suspicious charge calculations: 172 (2.4%)\n",
      "   üí° Small number of suspicious charges - likely due to promotions/discounts\n",
      "   ‚úÖ Keeping all records (realistic business scenario)\n"
     ]
    }
   ],
   "source": [
    "# 5. Validate business logic\n",
    "print(f\"\\n5Ô∏è‚É£ Validating business logic...\")\n",
    "\n",
    "# Check if TotalCharges makes sense with tenure and MonthlyCharges\n",
    "df_cleaned['ExpectedTotalCharges'] = df_cleaned['tenure'] * df_cleaned['MonthlyCharges']\n",
    "df_cleaned['ChargesDifference'] = abs(df_cleaned['TotalCharges'] - df_cleaned['ExpectedTotalCharges'])\n",
    "\n",
    "# Allow for some variance (promotions, price changes, etc.)\n",
    "threshold = df_cleaned['MonthlyCharges'] * 3  # 3 months worth of charges difference\n",
    "suspicious_charges = df_cleaned['ChargesDifference'] > threshold\n",
    "suspicious_count = suspicious_charges.sum()\n",
    "\n",
    "print(f\"   Customers with suspicious charge calculations: {suspicious_count} ({suspicious_count/len(df_cleaned)*100:.1f}%)\")\n",
    "\n",
    "if suspicious_count > 0 and suspicious_count < len(df_cleaned) * 0.1:  # Less than 10%\n",
    "    print(\"   üí° Small number of suspicious charges - likely due to promotions/discounts\")\n",
    "    print(\"   ‚úÖ Keeping all records (realistic business scenario)\")\n",
    "elif suspicious_count > len(df_cleaned) * 0.1:\n",
    "    print(\"   ‚ö†Ô∏è High number of suspicious charges - data quality issue\")\n",
    "\n",
    "# Remove the temporary calculation columns\n",
    "df_cleaned = df_cleaned.drop(['ExpectedTotalCharges', 'ChargesDifference'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e42516eb-b5f1-4a23-9657-417f93b5a69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6Ô∏è‚É£ Standardizing categorical values...\n",
      "   gender: ['Female' 'Male']\n",
      "   Partner: ['Yes' 'No']\n",
      "   Dependents: ['No' 'Yes']\n",
      "   PhoneService: ['No' 'Yes']\n",
      "   MultipleLines: ['No phone service' 'No' 'Yes']\n",
      "   üîß Standardizing 'No phone service' values in MultipleLines\n",
      "   InternetService: ['DSL' 'Fiber optic' 'No']\n",
      "   OnlineSecurity: ['No' 'Yes' 'No internet service']\n",
      "   üîß Standardizing 'No internet service' values in OnlineSecurity\n",
      "   OnlineBackup: ['Yes' 'No' 'No internet service']\n",
      "   üîß Standardizing 'No internet service' values in OnlineBackup\n",
      "   DeviceProtection: ['No' 'Yes' 'No internet service']\n",
      "   üîß Standardizing 'No internet service' values in DeviceProtection\n",
      "   TechSupport: ['No' 'Yes' 'No internet service']\n",
      "   üîß Standardizing 'No internet service' values in TechSupport\n",
      "   StreamingTV: ['No' 'Yes' 'No internet service']\n",
      "   üîß Standardizing 'No internet service' values in StreamingTV\n",
      "   StreamingMovies: ['No' 'Yes' 'No internet service']\n",
      "   üîß Standardizing 'No internet service' values in StreamingMovies\n",
      "   Contract: ['Month-to-month' 'One year' 'Two year']\n",
      "   PaperlessBilling: ['Yes' 'No']\n",
      "   PaymentMethod: ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "   Churn: ['No' 'Yes']\n",
      "\n",
      "‚úÖ Data cleaning completed!\n",
      "üìä Final dataset: 7,043 rows √ó 21 columns\n"
     ]
    }
   ],
   "source": [
    "# 6. Standardize categorical values\n",
    "print(f\"\\n6Ô∏è‚É£ Standardizing categorical values...\")\n",
    "categorical_cols = df_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'customerID' in categorical_cols:\n",
    "    categorical_cols.remove('customerID')\n",
    "\n",
    "for col in categorical_cols:\n",
    "    unique_values = df_cleaned[col].unique()\n",
    "    print(f\"   {col}: {unique_values}\")\n",
    "\n",
    "    # Check for common inconsistencies\n",
    "    if any('no phone service' in str(val).lower() for val in unique_values):\n",
    "        print(f\"   üîß Standardizing 'No phone service' values in {col}\")\n",
    "        df_cleaned[col] = df_cleaned[col].replace('No phone service', 'No')\n",
    "\n",
    "    if any('no internet service' in str(val).lower() for val in unique_values):\n",
    "        print(f\"   üîß Standardizing 'No internet service' values in {col}\")\n",
    "        df_cleaned[col] = df_cleaned[col].replace('No internet service', 'No')\n",
    "\n",
    "print(f\"\\n‚úÖ Data cleaning completed!\")\n",
    "print(f\"üìä Final dataset: {df_cleaned.shape[0]:,} rows √ó {df_cleaned.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a062a41b-a0d0-4638-a298-c3f570a86a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Dataset ready for exploratory data analysis!\n",
      "\n",
      "üîç Post-cleaning validation:\n",
      "   Missing values: 0\n",
      "   Duplicate customers: 0\n",
      "   Data types: {dtype('O'): 17, dtype('int64'): 2, dtype('float64'): 2}\n",
      "\n",
      "üíæ Cleaned dataset ready for analysis\n",
      "   Shape: (7043, 21)\n",
      "   Memory usage: 6.3 MB\n",
      "\n",
      " Cleaned and Processed Dataset is ready for further analysis\n"
     ]
    }
   ],
   "source": [
    "# Summary of changes\n",
    "rows_removed = original_shape[0] - df_cleaned.shape[0]\n",
    "if rows_removed > 0:\n",
    "    print(f\"üóëÔ∏è Removed {rows_removed} rows ({rows_removed/original_shape[0]*100:.1f}%)\")\n",
    "\n",
    "print(f\"üéØ Dataset ready for exploratory data analysis!\")\n",
    "\n",
    "# Quick validation\n",
    "print(f\"\\nüîç Post-cleaning validation:\")\n",
    "print(f\"   Missing values: {df_cleaned.isnull().sum().sum()}\")\n",
    "print(f\"   Duplicate customers: {df_cleaned['customerID'].duplicated().sum()}\")\n",
    "print(f\"   Data types: {df_cleaned.dtypes.value_counts().to_dict()}\")\n",
    "\n",
    "# Save cleaned data reference\n",
    "print(f\"\\nüíæ Cleaned dataset ready for analysis\")\n",
    "print(f\"   Shape: {df_cleaned.shape}\")\n",
    "print(f\"   Memory usage: {df_cleaned.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Save for future analysis\n",
    "df_cleaned.to_csv('../data/clean-processed-data.csv')\n",
    "print(f\"\\n Cleaned and Processed Dataset is ready for further analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL/GenAI",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
